services:
  # ==========================================
  # PHASE 4.2: PgBouncer - Connection Pooling
  # ==========================================
  pgbouncer:
    build:
      context: .
      dockerfile: Dockerfile.pgbouncer
    container_name: fileshare-pgbouncer
    ports:
      - "6432:6432"
      - "6431:6431"
    environment:
      - PGBOUNCER_DATABASES=fileshare
      - PGBOUNCER_POOL_MODE=transaction
      - PGBOUNCER_MAX_CLIENT_CONN=1000
      - PGBOUNCER_DEFAULT_POOL_SIZE=25
    volumes:
      - ./pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ./pgbouncer_userlist.txt:/etc/pgbouncer/userlist.txt:ro
      - pgbouncer-logs:/var/log/pgbouncer
    depends_on:
      - postgres-master
      - postgres-standby1
      - postgres-standby2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6431/stats"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # PHASE 4.1: etcd - Consensus store cho Patroni
  # ==========================================
  etcd:
    image: quay.io/coreos/etcd:v3.5
    container_name: fileshare-etcd
    ports:
      - "2379:2379"
      - "2380:2380"
    environment:
      - ETCD_NAME=etcd-node1
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd:2380
      - ETCD_INITIAL_CLUSTER=etcd-node1=http://etcd:2380
      - ETCD_INITIAL_CLUSTER_STATE=new
      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster
    volumes:
      - etcd-data:/etcd-data
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # Gateway API - Entry point cho client
  # ==========================================
  gateway:
    build:
      context: .
      dockerfile: Dockerfile.gateway
    container_name: fileshare-gateway
    ports:
      - "5000:5000"
    environment:
      - FLASK_HOST=0.0.0.0
      - FLASK_PORT=5000
      - DATABASE_URL=postgresql://postgres:postgres_secure_pass@postgres-master:5432/fileshare
      - DATABASE_READ_URL=postgresql://postgres:postgres_secure_pass@postgres-standby1:5432/fileshare
      - DATABASE_POOL_URL=postgresql://postgres:postgres_secure_pass@pgbouncer:6432/fileshare
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
      - REDIS_SENTINEL_HOST=redis-sentinel1
      - REDIS_SENTINEL_PORT=26379
      - REDIS_SENTINEL_MASTER=fileshare-master
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - NODE1_URL=http://storage-node1:8000
      - NODE2_URL=http://storage-node2:8000
      - NODE3_URL=http://storage-node3:8000
    volumes:
      - gateway-data:/app/data
      - gateway-logs:/app/logs
    depends_on:
      - storage-node1
      - storage-node2
      - storage-node3
      - rabbitmq
      - etcd
      - pgbouncer
      - postgres-master
      - postgres-standby1
      - postgres-standby2
      - redis-master
      - redis-slave1
      - redis-slave2
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # Storage Node 1 - Independent storage service
  # ==========================================
  storage-node1:
    build:
      context: .
      dockerfile: Dockerfile.storage
    container_name: fileshare-node1
    environment:
      - NODE_ID=node1
      - STORAGE_PATH=/data
      - PORT=8000
    volumes:
      - node1-data:/data
    ports:
      - "8001:8000"
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # Storage Node 2 - Independent storage service
  # ==========================================
  storage-node2:
    build:
      context: .
      dockerfile: Dockerfile.storage
    container_name: fileshare-node2
    environment:
      - NODE_ID=node2
      - STORAGE_PATH=/data
      - PORT=8000
    volumes:
      - node2-data:/data
    ports:
      - "8002:8000"
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # Storage Node 3 - Independent storage service
  # ==========================================
  storage-node3:
    build:
      context: .
      dockerfile: Dockerfile.storage
    container_name: fileshare-node3
    environment:
      - NODE_ID=node3
      - STORAGE_PATH=/data
      - PORT=8000
    volumes:
      - node3-data:/data
    ports:
      - "8003:8000"
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # Worker Services - Image processing
  # ==========================================
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - DATABASE_URL=postgresql://postgres:postgres_secure_pass@postgres-master:5432/fileshare
      - DATABASE_READ_URL=postgresql://postgres:postgres_secure_pass@postgres-standby1:5432/fileshare
      - DATABASE_POOL_URL=postgresql://postgres:postgres_secure_pass@pgbouncer:6432/fileshare
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
      - REDIS_SENTINEL_HOST=redis-sentinel1
      - REDIS_SENTINEL_PORT=26379
      - REDIS_SENTINEL_MASTER=fileshare-master
      - RABBITMQ_HOST=rabbitmq
      - RABBITMQ_PORT=5672
      - NODE1_URL=http://storage-node1:8000
      - NODE2_URL=http://storage-node2:8000
      - NODE3_URL=http://storage-node3:8000
    volumes:
      - worker-logs:/app/logs
    depends_on:
      - rabbitmq
      - pgbouncer
      - postgres-master
      - postgres-standby1
      - postgres-standby2
      - redis-master
      - redis-slave1
      - redis-slave2
      - gateway
    networks:
      - fileshare-network
    restart: unless-stopped
    deploy:
      replicas: 2

  # ==========================================
  # RabbitMQ - Message Queue
  # ==========================================
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: fileshare-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # PHASE 4: PostgreSQL Master-Slave Replication
  # ==========================================

  # PostgreSQL Master with Patroni
  postgres-master:
    image: patroni:2.1-pg15
    container_name: postgres-master
    ports:
      - "5432:5432"
      - "8008:8008"
    environment:
      - PATRONI_SCOPE=fileshare-cluster
      - PATRONI_ETCD3_HOSTS=etcd:2379
      - PATRONI_POSTGRESQL_DATA_DIR=/var/lib/postgresql/data/pgdata
      - PATRONI_POSTGRESQL_AUTHENTICATION_USERNAME=postgres
      - PATRONI_POSTGRESQL_AUTHENTICATION_PASSWORD=postgres_secure_pass
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_CONNECTIONS=200
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_WAL_SENDERS=10
      - PATRONI_POSTGRESQL_PARAMETERS_WAL_KEEP_SIZE=1GB
      - PATRONI_POSTGRESQL_PARAMETERS_SHARED_BUFFERS=256MB
      - PATRONI_SUPERUSER_USERNAME=postgres
      - PATRONI_SUPERUSER_PASSWORD=postgres_secure_pass
      - PATRONI_REPLICATION_USERNAME=replicator
      - PATRONI_REPLICATION_PASSWORD=replicator_pass_secure
      - PATRONI_RESTAPI_LISTEN=0.0.0.0:8008
      - PATRONI_RESTAPI_CONNECT_ADDRESS=postgres-master:8008
    volumes:
      - postgres-master-data:/var/lib/postgresql/data
      - ./postgres_config/patroni-master.yml:/etc/patroni/patroni.yml:ro
    depends_on:
      - etcd
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - fileshare-network
    restart: unless-stopped

  # PostgreSQL Standby 1 with Patroni
  postgres-standby1:
    image: patroni:2.1-pg15
    container_name: postgres-standby1
    ports:
      - "5433:5432"
      - "8009:8008"
    environment:
      - PATRONI_SCOPE=fileshare-cluster
      - PATRONI_ETCD3_HOSTS=etcd:2379
      - PATRONI_POSTGRESQL_DATA_DIR=/var/lib/postgresql/data/pgdata
      - PATRONI_POSTGRESQL_AUTHENTICATION_USERNAME=postgres
      - PATRONI_POSTGRESQL_AUTHENTICATION_PASSWORD=postgres_secure_pass
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_CONNECTIONS=200
      - PATRONI_POSTGRESQL_PARAMETERS_HOT_STANDBY=on
      - PATRONI_POSTGRESQL_PARAMETERS_HOT_STANDBY_FEEDBACK=on
      - PATRONI_SUPERUSER_USERNAME=postgres
      - PATRONI_SUPERUSER_PASSWORD=postgres_secure_pass
      - PATRONI_REPLICATION_USERNAME=replicator
      - PATRONI_REPLICATION_PASSWORD=replicator_pass_secure
      - PATRONI_RESTAPI_LISTEN=0.0.0.0:8008
      - PATRONI_RESTAPI_CONNECT_ADDRESS=postgres-standby1:8008
    volumes:
      - postgres-standby1-data:/var/lib/postgresql/data
      - ./postgres_config/patroni-standby.yml:/etc/patroni/patroni.yml:ro
    depends_on:
      - etcd
      - postgres-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - fileshare-network
    restart: unless-stopped

  # PostgreSQL Standby 2 with Patroni
  postgres-standby2:
    image: patroni:2.1-pg15
    container_name: postgres-standby2
    ports:
      - "5434:5432"
      - "8010:8008"
    environment:
      - PATRONI_SCOPE=fileshare-cluster
      - PATRONI_ETCD3_HOSTS=etcd:2379
      - PATRONI_POSTGRESQL_DATA_DIR=/var/lib/postgresql/data/pgdata
      - PATRONI_POSTGRESQL_AUTHENTICATION_USERNAME=postgres
      - PATRONI_POSTGRESQL_AUTHENTICATION_PASSWORD=postgres_secure_pass
      - PATRONI_POSTGRESQL_PARAMETERS_MAX_CONNECTIONS=200
      - PATRONI_POSTGRESQL_PARAMETERS_HOT_STANDBY=on
      - PATRONI_POSTGRESQL_PARAMETERS_HOT_STANDBY_FEEDBACK=on
      - PATRONI_SUPERUSER_USERNAME=postgres
      - PATRONI_SUPERUSER_PASSWORD=postgres_secure_pass
      - PATRONI_REPLICATION_USERNAME=replicator
      - PATRONI_REPLICATION_PASSWORD=replicator_pass_secure
      - PATRONI_RESTAPI_LISTEN=0.0.0.0:8008
      - PATRONI_RESTAPI_CONNECT_ADDRESS=postgres-standby2:8008
    volumes:
      - postgres-standby2-data:/var/lib/postgresql/data
      - ./postgres_config/patroni-standby.yml:/etc/patroni/patroni.yml:ro
    depends_on:
      - etcd
      - postgres-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - fileshare-network
    restart: unless-stopped

  # ==========================================
  # PHASE 3: Redis Master-Slave Cluster with Sentinel
  # ==========================================

  # Redis Master
  redis-master:
    image: redis:7-alpine
    container_name: redis-master
    ports:
      - "6379:6379"
    volumes:
      - redis-master-data:/data
    networks:
      - fileshare-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Redis Slave 1
  redis-slave1:
    image: redis:7-alpine
    container_name: redis-slave1
    ports:
      - "6380:6380"
    volumes:
      - redis-slave1-data:/data
    networks:
      - fileshare-network
    restart: unless-stopped
    command: redis-server --port 6380 --slaveof redis-master 6379 --appendonly yes
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "6380", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Redis Slave 2
  redis-slave2:
    image: redis:7-alpine
    container_name: redis-slave2
    ports:
      - "6381:6381"
    volumes:
      - redis-slave2-data:/data
    networks:
      - fileshare-network
    restart: unless-stopped
    command: redis-server --port 6381 --slaveof redis-master 6379 --appendonly yes
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "6381", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Redis Sentinel 1 - TODO: Configure with proper startup script
  # redis-sentinel1:
  #   image: redis:7-alpine
  #   container_name: redis-sentinel1
  #   ports:
  #     - "26379:26379"
  #   volumes:
  #     - redis-sentinel1-data:/data
  #   networks:
  #     - fileshare-network
  #   restart: unless-stopped
  #   depends_on:
  #     - redis-master
  #     - redis-slave1
  #     - redis-slave2

  # redis-sentinel2:
  #   image: redis:7-alpine
  #   container_name: redis-sentinel2
  #   ports:
  #     - "26380:26380"
  #   volumes:
  #     - redis-sentinel2-data:/data
  #   networks:
  #     - fileshare-network
  #   restart: unless-stopped
  #   depends_on:
  #     - redis-master
  #     - redis-slave1
  #     - redis-slave2

  # redis-sentinel3:
  #   image: redis:7-alpine
  #   container_name: redis-sentinel3
  #   ports:
  #     - "26381:26381"
  #   volumes:
  #     - redis-sentinel3-data:/data
  #   networks:
  #     - fileshare-network
  #   restart: unless-stopped
  #   depends_on:
  #     - redis-master
  #     - redis-slave1
  #     - redis-slave2

# ==========================================
# Docker Volumes - Persistent storage
# ==========================================
volumes:
  gateway-data:
  gateway-logs:
  node1-data:
  node2-data:
  node3-data:
  worker-logs:
  rabbitmq-data:
  etcd-data:
  pgbouncer-logs:
  redis-master-data:
  redis-slave1-data:
  redis-slave2-data:
  postgres-master-data:
  postgres-standby1-data:
  postgres-standby2-data:

# ==========================================
# Docker Network - Internal communication
# ==========================================
networks:
  fileshare-network:
    driver: bridge
